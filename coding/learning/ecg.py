# -*- coding: utf-8 -*-
"""ECG.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qyhjhjcAa9q87zXtEfUT6VcMDvs_1KAB

## Imports
"""

import io
import PIL.Image as Image
import ast
import os

from torchvision.datasets import ImageFolder
from tqdm import tqdm
import matplotlib.pyplot as plt
import torch
import torchvision
import numpy as np
from torch import nn
import torch.nn.functional as F
import pytorch_lightning as pl
from pytorch_lightning.callbacks import Callback, ModelCheckpoint
from pytorch_lightning.callbacks.early_stopping import EarlyStopping
from pytorch_lightning.metrics.functional import accuracy
from pytorch_lightning.loggers import TensorBoardLogger
import pickle
from torchvision import transforms
from torch.utils.data import DataLoader, random_split, Dataset

# setting device on GPU if available, else CPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Using device:', device)
if device == torch.device('cuda'):
  print(torch.cuda.get_device_name(0))

# Reproducibility
seed = 7
torch.manual_seed(seed)
np.random.seed(seed)

"""## Data"""

# Setting credentials using the downloaded JSON file
# path = '/Users/barakm/Desktop/TAU/signal_processing/ECG-Arrhythmia-Classification/model-azimuth-321409-241148a4b144.json' # 'model-azimuth-321409-241148a4b144.json'
# if not os.path.isfile(path):
#     raise ("Please provide the gcs key in the root directory")
# # client = storage.Client.from_service_account_json(json_credentials_path=path)
# client = storage.Client.from_service_account_json(json_credentials_path=path)
# bucket = client.get_bucket('ecg-arrhythmia-classification')

# from torchvision.datasets.cifar import CIFAR10

# class PtbData(Dataset):
#
#     def __init__(self, data_map_url, gender, under_50, is_train, download=False, transform=None):
#         """
#         Args:
#
#         """
#
#         self.gender = gender
#         self.under_50 = under_50
#         self.transform = transform
#         self.state = 'train' if is_train else 'test'
#
#         if download:
#             blob_obj = bucket.blob(data_map_url)
#             self.data_map = ast.literal_eval(blob_obj.download_as_string().decode('utf-8'))
#             self.data_map[self.state][self.gender][self.under_50]['A'] +=\
#                self.data_map[self.state][self.gender][self.under_50]['B'] +\
#                self.data_map[self.state][self.gender]['>=' if self.under_50 else '<']['A'] +\
#                self.data_map[self.state][self.gender]['>=' if self.under_50 else '<']['B']
#
#             self.data_map[self.state][self.gender][self.under_50]['Y_A'] +=\
#                self.data_map[self.state][self.gender][self.under_50]['Y_B']+\
#                self.data_map[self.state][self.gender]['>=' if self.under_50 else '<']['Y_A'] +\
#                self.data_map[self.state][self.gender]['>=' if self.under_50 else '<']['Y_B']
#
#             self.data_map[self.state][self.gender][self.under_50]['meta_A'] +=\
#                self.data_map[self.state][self.gender][self.under_50]['meta_B'] +\
#                self.data_map[self.state][self.gender]['>=' if self.under_50 else '<']['meta_A'] +\
#                self.data_map[self.state][self.gender]['>=' if self.under_50 else '<']['meta_B']
#
#             if not os.path.isdir('./images') or len(os.listdir('./images')) < 1:
#                 os.mkdir('./images')
#                 self.labels = []
#                 label_count = np.unique(self.data_map[self.state][self.gender][self.under_50]['Y_A'], return_counts=True)
#                 num_samples_each_class = 3*np.min(label_count[1])
#                 class_count = np.zeros(len(label_count[0]))
#                 catagory_data_len = len(self.data_map[self.state][self.gender][self.under_50]['A'])
#                 for ii in tqdm(np.random.permutation(catagory_data_len)):
#                     label = self.data_map[self.state][self.gender][self.under_50]['Y_A'][ii]
#                     if class_count[label] >= num_samples_each_class:
#                         continue
#                     class_count[label] += 1
#                     blob_obj = bucket.blob("{}".format(self.data_map[self.state][self.gender][self.under_50]['A'][ii]))
#                     sample = Image.open(io.BytesIO(blob_obj.download_as_bytes())).convert('L')
#                     age = int(self.data_map[self.state][self.gender][self.under_50]['meta_A'][ii]['age'])
#                     sex = self.data_map[self.state][self.gender][self.under_50]['meta_A'][ii]['sex']
#
#                     sample.save('./images/' + str(ii) + '_label_' + str(label) + '_age' + str(age) + '_sex' + str(sex) + '.jpeg')
#                     self.labels.append(label)
#
#                     if np.all(class_count >= num_samples_each_class):
#                         break
#
#                 with open('labels.pickle', 'wb') as handle:
#                     pickle.dump(self.labels, handle, protocol=pickle.HIGHEST_PROTOCOL)
#
#             self.files = os.listdir('./images')
#             with open('data_map.pickle', 'wb') as handle:
#                 pickle.dump(self.data_map, handle, protocol=pickle.HIGHEST_PROTOCOL)
#
#         else:
#             self.files = os.listdir('./images')
#             with open('data_map.pickle', 'rb') as handle:
#                 self.data_map = pickle.load(handle)
#
#         with open('labels.pickle', 'rb') as handle:
#             self.labels = pickle.load(handle)
#
#     def __len__(self):
#         # len(self.data_map[self.state][self.gender][self.under_50]['A']) # +\
#         # len(self.data_map[self.state][self.gender][self.under_50]['B'])
#         return len(self.files)
#
#     def __getitem__(self, idx):
#         # blob_obj = bucket.blob("{}".format(self.data_map[self.state][self.gender][self.under_50]['A'][idx]))
#         # sample = pickle.loads(blob_obj.download_as_bytes())
#         # sample = Image.open(io.BytesIO(blob_obj.download_as_bytes())).convert('L')
#         sample = Image.open('./images/' + self.files[idx])
#         # y = self.data_map[self.state][self.gender][self.under_50]['Y_A'][idx]
#         y = int(self.files[idx].split('label_')[1].split('_')[0])
#         if self.transform:
#             sample = self.transform(sample)
#         return sample, y


class STFT(pl.LightningDataModule):
    def __init__(self, batch_size, image_folder_path, transform=None):
        super().__init__()

        self.batch_size = batch_size
        self.image_folder_path = image_folder_path

        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Grayscale(num_output_channels=1),
            transforms.Normalize((0.5), (0.5))
        ])

    def prepare_data(self):
        # download
        # PtbData(self.data_map_url, self.gender, self.under_50, self.state, download=True, transform=self.transform)
        pass

    def setup(self, stage=None):
        # Assign train/val datasets for use in dataloaders
        dataset = ImageFolder(self.image_folder_path, self.transform)
        if stage == 'train' or stage is None:
            self.train, self.val = random_split(dataset,
                                                [int(len(dataset)*0.8),
                                                 len(dataset) - int(len(dataset)*0.8)])
            # ptb_full = PtbData(self.data_map_url, self.gender, self.under_50, 'train', transform=self.transform)
            # self.train, self.val = random_split(ptb_full, [round(len(ptb_full)*0.85), len(ptb_full) - round(len(ptb_full)*0.85)])
            print('len all data: ', len(dataset))
            print('len train: ', len(self.train))
            print('len val: ', len(self.val))

        # Assign test dataset for use in dataloader(s)
        if stage == 'test' or stage is None:
            self.test = dataset if stage == 'test' else self.val
            # self.test = PtbData(self.data_map_url, self.gender, self.under_50, 'test', transform=self.transform)
            print('len test: ', len(self.test))

    def train_dataloader(self):
        return DataLoader(self.train, batch_size=self.batch_size, shuffle=True, drop_last=True, num_workers=4)

    def val_dataloader(self):
        return DataLoader(self.val, batch_size=self.batch_size, num_workers=4)

    def test_dataloader(self):
        return DataLoader(self.test, batch_size=self.batch_size, num_workers=4)


class Wavelet(pl.LightningDataModule):
    def __init__(self, batch_size, image_folder_path, transform=None):
        super().__init__()

        self.batch_size = batch_size
        self.image_folder_path = image_folder_path

        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Grayscale(num_output_channels=1),
            transforms.Normalize((0.5), (0.5))
        ])

    def prepare_data(self):
        # download
        # PtbData(self.data_map_url, self.gender, self.under_50, self.state, download=True, transform=self.transform)
        pass

    def setup(self, stage=None):
        # Assign train/val datasets for use in dataloaders
        dataset = ImageFolder(self.image_folder_path, self.transform)
        if stage == 'train' or stage is None:
            self.train, self.val = random_split(dataset,
                                                [int(len(dataset)*0.8),
                                                 len(dataset) - int(len(dataset)*0.8)])
            # ptb_full = PtbData(self.data_map_url, self.gender, self.under_50, 'train', transform=self.transform)
            # self.train, self.val = random_split(ptb_full, [round(len(ptb_full)*0.85), len(ptb_full) - round(len(ptb_full)*0.85)])
            print('len all data: ', len(dataset))
            print('len train: ', len(self.train))
            print('len val: ', len(self.val))

        # Assign test dataset for use in dataloader(s)
        if stage == 'test' or stage is None:
            self.test = dataset if stage == 'test' else self.val
            # self.test = PtbData(self.data_map_url, self.gender, self.under_50, 'test', transform=self.transform)
            print('len test: ', len(self.test))

    def train_dataloader(self):
        return DataLoader(self.train, batch_size=self.batch_size, shuffle=True, drop_last=True, num_workers=4)

    def val_dataloader(self):
        return DataLoader(self.val, batch_size=self.batch_size, num_workers=4)

    def test_dataloader(self):
        return DataLoader(self.test, batch_size=self.batch_size, num_workers=4)

def loader(path):


class PaperNet(pl.LightningModule):
    """## Model"""
    def __init__(self, input_shape, num_classes, loss_weights, device, learning_rate, weight_decay, batch_size, drop_prob=0):
        super().__init__()

        # log hyper-parameters
        self.learning_rate = learning_rate
        self.loss_weights = loss_weights
        self.weight_decay = weight_decay
        self.batch_size = batch_size
        self.drop_prob = drop_prob
        self.num_features_fc = 15
        self.save_hyperparameters()

        self.features = nn.Sequential(
            nn.Conv2d(1, 8, 4),
            nn.BatchNorm2d(8),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(8, 13, 3),
            nn.BatchNorm2d(13),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(13, 13, 3),
            nn.BatchNorm2d(13),
            nn.ReLU(),
            nn.MaxPool2d(2)
        ).to(device)

        self.features_num = self._get_conv_output(input_shape)

        self.classifier = nn.Sequential(
            nn.Linear(self.features_num, self.num_features_fc),
            nn.BatchNorm1d(self.num_features_fc),
            nn.ReLU(),
            nn.Dropout2d(p=drop_prob),
            nn.Linear(self.num_features_fc, num_classes),
            nn.Softmax(-1)
        ).to(device)

    # returns the size of the output tensor going into Linear layer from the conv block.
    def _get_conv_output(self, shape):
        batch_size = 1
        input = torch.autograd.Variable(torch.rand(batch_size, *shape)).cuda()

        output_feat = self.features(input)
        n_size = output_feat.data.view(batch_size, -1).size(1)
        return n_size

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y, weight=self.loss_weights)

        # training metrics
        # preds = torch.argmax(logits, dim=1)
        # acc = accuracy(preds, y)
        # self.log('train_loss11', loss, on_step=True, on_epoch=True, logger=True)
        # self.log('train_acc11', acc, on_step=True, on_epoch=True, logger=True)

        correct = (torch.argmax(logits, -1) == y).sum()
        total = torch.numel(y)

        batch_dict = {
            "loss": loss,
            'correct': correct,
            "total": total
        }

        return batch_dict

    def training_epoch_end(self, outputs):
        #  the function is called after every epoch is completed

        # calculating average loss
        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()

        # calculating correct and total predictions
        correct = sum([x["correct"] for x in outputs])
        total = sum([x["total"] for x in outputs])
        acc = correct / total

        self.logger.experiment.add_scalar('train_loss Epoch', avg_loss, self.trainer.current_epoch)
        self.logger.experiment.add_scalar('train_acc Epoch', acc, self.trainer.current_epoch)

    def validation_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        
        loss = F.nll_loss(logits, y, weight=self.loss_weights)

        correct = (torch.argmax(logits, -1) == y).sum()
        total = torch.numel(y)

        batch_dict = {
            "loss": loss,
            'correct': correct,
            "total": total
        }

        return batch_dict

    def validation_epoch_end(self, outputs):
        #  the function is called after every epoch is completed

        # calculating average loss
        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()

        # calculating correct and total predictions
        correct = sum([x["correct"] for x in outputs])
        total = sum([x["total"] for x in outputs])
        acc = correct / total

        self.logger.experiment.add_scalar('val_loss Epoch', avg_loss, self.trainer.current_epoch)
        self.logger.experiment.add_scalar('val_acc Epoch', acc, self.trainer.current_epoch)

    def test_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y, weight=self.loss_weights)

        # validation metrics
        preds = torch.argmax(logits, dim=1)
        acc = accuracy(preds, y)
        self.log('test_loss', loss, prog_bar=True)
        self.log('test_acc', acc, prog_bar=True)

        correct = (torch.argmax(logits, -1) == y).sum()
        total = torch.numel(y)

        batch_dict = {
            "loss": loss,
            'correct': correct,
            "total": total
        }

        return batch_dict

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)
        return optimizer


class Net1(PaperNet):
    def __init__(self, input_shape, num_classes, loss_weights, device, learning_rate, weight_decay, batch_size):
        super().__init__(input_shape, num_classes, loss_weights, device, learning_rate, weight_decay, batch_size)

        self.features = nn.Sequential(
            nn.Conv2d(1, 64, 4),
            nn.BatchNorm2d(64),
            nn.Dropout2d(p=0.2),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 2),
            nn.BatchNorm2d(128),
            nn.Dropout2d(p=0.2),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(128, 128, 2),
            nn.BatchNorm2d(128),
            nn.Dropout2d(p=0.2),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(128, 64, 2),
            nn.BatchNorm2d(64),
            nn.Dropout2d(p=0.2),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 32, 2),
            nn.BatchNorm2d(32),
            nn.Dropout2d(p=0.2),
            nn.ReLU(),
            nn.MaxPool2d(2)
        ).to(device)

        self.features_num = self._get_conv_output(input_shape)

        self.classifier = nn.Sequential(
            nn.Linear(self.features_num, 128),
            nn.BatchNorm1d(128),
            nn.Dropout2d(p=0.3),
            nn.ReLU(),
            nn.Linear(128, num_classes),
            nn.Softmax(-1)
        ).to(device)


class ImagePredictionLogger(Callback):
    def __init__(self, val_samples, classes_names, num_samples=20):
        super().__init__()
        self.num_samples = num_samples
        self.val_imgs, self.val_labels = val_samples
        self.classes_names = classes_names

    def on_validation_epoch_end(self, trainer, pl_module):
        # Bring the tensors to CPU
        val_imgs = self.val_imgs.to(device=pl_module.device)
        val_labels = self.classes_names[self.val_labels]#.to(device=pl_module.device)
        # Get model prediction
        logits = pl_module(val_imgs)
        preds = self.classes_names[torch.argmax(logits, -1).cpu()]
        # Log the images

        fig = image_grid(val_imgs[:self.num_samples], val_labels[:self.num_samples], preds[:self.num_samples])
        trainer.logger.experiment.add_figure('Predictions', fig, global_step=trainer.current_epoch)
        # trainer.logger.experiment.log({
        #     "examples": [Image(x, caption=f"Pred:{pred}, Label:{y}")
        #                  for x, pred, y in zip(val_imgs[:self.num_samples],
        #                                        preds[:self.num_samples],
        #                                        val_labels[:self.num_samples])]
        # })


def image_grid(images, labels, preds):
    figure = plt.figure(figsize=(12, 8))

    num_imgs_to_plot = 16
    for ii, x, y, pred in zip(range(num_imgs_to_plot), images[:num_imgs_to_plot],
                              labels[:num_imgs_to_plot], preds[:num_imgs_to_plot]):
        plt.subplot(int(np.sqrt(num_imgs_to_plot)), int(np.sqrt(num_imgs_to_plot)), ii + 1)
        plt.title('label: ' + y + '. pred: ' + pred)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(x[0].cpu().numpy(), cmap=plt.cm.coolwarm)

    return figure

# class OneDimNet()
#     def __init__(self, input_shape, num_classes, loss_weights, device, learning_rate, weight_decay):
#         super().__init__(input_shape, num_classes, loss_weights, device, learning_rate, weight_decay)
#         self.features = nn.Sequencial(
#             nn.Linear(input_shape[1]*input_shape[2], 64),
#             nn.BatchNorm1d(64),
#             nn.Dropout2d(p=0.3),
#             nn.ReLU(),
#             nn.Linear(64, 32),
#             nn.BatchNorm1d(32),
#             nn.Dropout2d(p=0.3),
#             nn.ReLU()
#         )

#         self.classifier = nn.Sequencial(
#             nn.Linear(32, 32),
#             nn.BatchNorm1d(32),
#             nn.Dropout2d(p=0.3),
#             nn.ReLU(),
#             nn.Linear(32, 32),
#             nn.BatchNorm1d(32),
#             nn.Dropout2d(p=0.3),
#             nn.ReLU(),
#             nn.Linear(32, 32),
#             nn.Softmax(-1)
#         )

#     def forward(self, x):
#         x = x.view(x.size(0), -1)
#         x = self.features(x)
#         x = self.classifier(x)
#         return x


for batch_loop in [128]:#[32, 64, 128]:
    for lr_loop in [1e-4]:#, 1e-4, 5e-5, 1e-6]:
        print(batch_loop)
        print(lr_loop)

        """## Training"""
        print('Training Started!')
        batch_size = batch_loop
        input_shape = (1, 256, 256)

        super_classes = np.array(["CD", "HYP", "MI", "NORM", "STTC"])
        data_path = '/inputs/TAU/SP/data/stft_norm' # '/inputs/TAU/SP/data/STFT' (all data)  # '/inputs/TAU/SP/data/stft_norm' (only male)
        dm = STFT(batch_size, data_path)
        dm.prepare_data()
        # dm._has_setup_fit = False
        dm.setup()

        label_hist = list(np.unique(dm.train.dataset.targets, return_counts=True))
        label_hist[1] = label_hist[1] / sum(label_hist[1])

        # plt.hist(dm.val.dataset.targets)

        # Samples required by the custom ImagePredictionLogger callback to log image predictions.
        val_samples = next(iter(dm.val_dataloader()))
        val_imgs, val_labels = val_samples[0], val_samples[1]

        logger = TensorBoardLogger('runs', "NORM_STFT")


        MODEL_CKPT_PATH = 'model/'
        MODEL_CKPT = 'model/model-{epoch:02d}-{val_loss:.2f}'

        # Init our model
        lr = lr_loop
        weight_decay = 0.005
        drop_prob = 0
        loss_weights = torch.cuda.FloatTensor(label_hist[1])
        model = PaperNet(input_shape, len(super_classes), loss_weights, device, lr, weight_decay, batch_size, drop_prob)
        # model = Net1(input_shape, len(super_classes), loss_weights, device, lr, weight_decay, batch_size)

        trainer = pl.Trainer(
            logger=logger,    # TB integration
            log_every_n_steps=1,   # set the logging frequency
            gpus=1,                # use one GPU
            max_epochs=200,           # number of epochs
            # deterministic=True,     # keep it deterministic
            auto_lr_find=True,
            callbacks=[
                        ImagePredictionLogger(val_samples, super_classes),
                        ModelCheckpoint(monitor='val_loss', filename=MODEL_CKPT, save_top_k=1, mode='min')
                        #  EarlyStopping(monitor='val_loss',patience=3,verbose=False,mode='min')
                        ]  # see Callbacks section
            )

        # Train the model âš¡ðŸš…âš¡
        trainer.fit(model, datamodule=dm)

        # evaluate the model on a test set
        trainer.test(model, datamodule=dm)  # uses last-saved model

print('Training Finished!')
