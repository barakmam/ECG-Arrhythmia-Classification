{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNVIZ7JFvHIpa3CqcgoVWb2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barakmam/ECG-Arrhythmia-Classification/blob/master/main2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHlixX1-FaKC"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pickle\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "def checkDevice():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.current_device()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # device = torch.device(\"cpu\")\n",
        "    print(\"running calculations on: \", device)\n",
        "    return device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJg6el3zNcwc"
      },
      "source": [
        "!wget -r -N -c -np https://physionet.org/files/mitdb/1.0.0/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m50vWEqDM55z"
      },
      "source": [
        "def trainNet(net, batch_size, learning_rate, step, patience, valCalcFreq, train_loader, val_loader, device):\n",
        "    # Print all of the hyperparameters of the training iteration:\n",
        "    print(\"===== HYPERPARAMETERS =====\")\n",
        "    print(\"batch_size=\", batch_size)\n",
        "    print(\"learning_rate=\", learning_rate)\n",
        "    print(\"step=\", step)\n",
        "    print(\"patience=\", patience)\n",
        "    print(\"=\" * 30)\n",
        "\n",
        "    # Time for printing\n",
        "    training_start_time = time.time()\n",
        "\n",
        "    # Statistics:\n",
        "    numDeleted = np.array([])\n",
        "    train_acc_total = np.array([])\n",
        "    val_acc_total = np.array([0])\n",
        "    train_loss_total = np.array([])\n",
        "    val_loss_total = np.array([])\n",
        "\n",
        "\n",
        "    delJumps = np.arange(12, 62, step)\n",
        "    n_epochJumps = 500 * np.ones(delJumps.shape)\n",
        "    for n_delete, n_epochs in zip(np.append([1, 2, 3, 4, 6, 8, 10], delJumps), np.append([5, 5, 5, 5, 5, 5,  5], n_epochJumps)):\n",
        "        print(f'Delete: {n_delete}.')\n",
        "\n",
        "        # for epoch in range(n_epochs):\n",
        "        epoch = 0\n",
        "        p = 0\n",
        "        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "        while p < patience:\n",
        "            epoch += 1\n",
        "            train_running_loss = 0.0\n",
        "            train_running_hits = 0.0\n",
        "            train_samples_checked = 0\n",
        "            runningDeletedNumber = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "            net.train()\n",
        "            for batch_idx, data in enumerate(train_loader, 0):\n",
        "\n",
        "                # Get inputs\n",
        "                _, solutions = data\n",
        "                solutions = solutions.float().to(device)\n",
        "                quizzes = delete_cells_improved_complexity(solutions, n_delete, device)\n",
        "                mask_of_deleted_cells = (quizzes.argmax(1) == 0).float()\n",
        "                # Set the parameter gradients to zero\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass, backward pass, optimize\n",
        "                outputs = net(quizzes)\n",
        "                loss_matrix, quizz_example, sol_example = loss_func(outputs, solutions)\n",
        "                loss_size = (mask_of_deleted_cells * loss_matrix).sum()/mask_of_deleted_cells.sum()\n",
        "                loss_size.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Update statstics:\n",
        "                train_running_loss += loss_size.data\n",
        "                train_running_hits += (\n",
        "                            (outputs.argmax(1) == solutions.argmax(1)).float() * mask_of_deleted_cells).sum().double()\n",
        "                # running_hits += ((solved_boards == solutions.argmax(1) + 1).float() * mask_of_deleted_cells).sum().double()\n",
        "                runningDeletedNumber += mask_of_deleted_cells.sum()\n",
        "                train_samples_checked += len(outputs)\n",
        "            train_acc_total = np.append(train_acc_total,\n",
        "                                        (train_running_hits / runningDeletedNumber).cpu().numpy())\n",
        "            train_loss_total = np.append(train_loss_total, (train_running_loss / len(train_loader)).cpu().numpy())\n",
        "            print(\"Delete {}  Epoch {}:\\tTook {:.2f}s. \\t Train: loss = {:.3f} Acc = {:.3f}\"\n",
        "                  .format(n_delete, epoch, time.time() - start_time, train_loss_total[-1], train_acc_total[-1]))\n",
        "\n",
        "            if epoch % valCalcFreq == 0:\n",
        "                # At the end of the epoch, do a pass on the validation set\n",
        "                val_start_time = time.time()\n",
        "                total_val_loss = 0\n",
        "                val_hits = 0\n",
        "                val_runningDeletedNumber = 0\n",
        "                val_samples_checked = 0\n",
        "                net.eval()\n",
        "                with torch.no_grad():\n",
        "                    for data in val_loader:\n",
        "                        # Wrap tensors in Variables\n",
        "                        _, val_solutions = data\n",
        "                        val_solutions = val_solutions.float().to(device)\n",
        "                        val_quizzes = delete_cells_improved_complexity(val_solutions, n_delete, device=device)\n",
        "                        val_mask_of_deleted_cells = (val_quizzes.argmax(1) == 0).float()\n",
        "                        # Forward pass\n",
        "                        # val_outputs = net(val_quizzes)\n",
        "                        val_solved_boards = fillBlank_imporved_complexity(net, val_quizzes, n_delete, device)\n",
        "                        val_iterative_outputs = torch_categorical(val_solved_boards - 1, 9, device)\n",
        "                        val_loss_matix, _, _ = loss_func(val_iterative_outputs, val_solutions)\n",
        "                        total_val_loss += (val_mask_of_deleted_cells * val_loss_matix).sum()/val_mask_of_deleted_cells.sum()\n",
        "                        # val_hits += ((val_outputs.argmax(1) == val_solutions.argmax(1)) * val_mask_of_deleted_cells).sum().double()\n",
        "                        val_hits += ((val_solved_boards == val_solutions.argmax(\n",
        "                            1) + 1).float() * val_mask_of_deleted_cells).sum().double()\n",
        "                        val_runningDeletedNumber += val_mask_of_deleted_cells.sum()\n",
        "                        val_samples_checked += len(val_solutions)\n",
        "\n",
        "                val_acc_total = np.append(val_acc_total, (val_hits / val_runningDeletedNumber).cpu().numpy())\n",
        "                val_loss_total = np.append(val_loss_total, (total_val_loss / len(val_loader)).cpu().numpy())\n",
        "                numDeleted = np.append(numDeleted, (val_runningDeletedNumber / val_samples_checked).cpu().numpy())\n",
        "                print(\"Delete {}  Epoch {}:\\tTook {:.2f}s. \\t Validation: loss = {:.3f} Acc = {:.3f}\"\n",
        "                      .format(n_delete, epoch, time.time() - val_start_time, val_loss_total[-1], val_acc_total[-1]))\n",
        "                if val_acc_total[-1] <= val_acc_total[-2]:\n",
        "                    p += 1\n",
        "                else:\n",
        "                    p = 0\n",
        "                if epoch == n_epochs:\n",
        "                    break\n",
        "\n",
        "    print(\"Training finished, took {:.3f}s\".format(time.time() - training_start_time))\n",
        "    return net, numDeleted, train_acc_total, train_loss_total, val_acc_total[1:], val_loss_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUJdcHmFM5nc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}